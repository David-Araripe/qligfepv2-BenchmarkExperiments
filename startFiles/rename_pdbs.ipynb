{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from QligFEP.pdb_utils import nest_pdb, unnest_pdb, read_pdb_to_dataframe, write_dataframe_to_pdb\n",
    "from QligFEP.CLI.pdb_to_amber import asp_search\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to remove Hs from GLY\n",
    "# Need to cap the last residue\n",
    "\n",
    "rename_mapping = {\n",
    "    'ARG': {\n",
    "        \"1HH1\": \"HH11\",\n",
    "        \"2HH1\": \"HH12\",\n",
    "        \"1HH2\": \"HH21\",\n",
    "        \"2HH2\": \"HH22\",\n",
    "        \"HA2\": \"HA3\",\n",
    "        \"HA1\": \"HA2\",\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "        \"HG2\": \"HG3\",\n",
    "        \"HG1\": \"HG2\",\n",
    "        \"HD2\": \"HD3\",\n",
    "        \"HD1\": \"HD2\",\n",
    "    },\n",
    "    'ILE': {\n",
    "        \"1HG2\": \"HG21\",\n",
    "        \"2HG2\": \"HG22\",\n",
    "        \"3HG2\": \"HG23\",\n",
    "        # HG1 with has the number +1 in our naming scheme\n",
    "        \"1HG1\": \"HG12\",\n",
    "        \"2HG1\": \"HG13\",\n",
    "        # this is fine...\n",
    "        \"CD\": \"CD1\",\n",
    "        \"HD1\": \"HD11\",\n",
    "        \"HD2\": \"HD12\",\n",
    "        \"HD3\": \"HD13\",\n",
    "    },\n",
    "    'THR': {\n",
    "        \"1HG2\": \"HG21\",\n",
    "        \"2HG2\": \"HG22\",\n",
    "        \"3HG2\": \"HG23\",\n",
    "    },\n",
    "    \"LEU\": {\n",
    "        \"1HD1\": \"HD11\",\n",
    "        \"2HD1\": \"HD12\",\n",
    "        \"3HD1\": \"HD13\",\n",
    "        \"1HD2\": \"HD21\",\n",
    "        \"2HD2\": \"HD22\",\n",
    "        \"3HD2\": \"HD23\",\n",
    "        \"HA2\": \"HA3\",\n",
    "        \"HA1\": \"HA2\",\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"GLN\": {\n",
    "        \"1HE2\": \"HE21\",\n",
    "        \"2HE2\": \"HE22\",\n",
    "        \"HA2\": \"HA3\",\n",
    "        \"HA1\": \"HA2\",\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "        \"HG2\": \"HG3\",\n",
    "        \"HG1\": \"HG2\",\n",
    "    },\n",
    "    \"GLY\": {\n",
    "        \"HA2\": \"HA3\",\n",
    "        \"HA1\": \"HA2\",\n",
    "    },\n",
    "    \"VAL\": {\n",
    "        \"1HG1\": \"HG11\",\n",
    "        \"2HG1\": \"HG12\",\n",
    "        \"3HG1\": \"HG13\",\n",
    "        \"1HG2\": \"HG21\",\n",
    "        \"2HG2\": \"HG22\",\n",
    "        \"3HG2\": \"HG23\",\n",
    "    },\n",
    "    \"SER\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"PHE\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"GLU\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "        \"HG2\": \"HG3\",\n",
    "        \"HG1\": \"HG2\",\n",
    "    },\n",
    "    \"ASP\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"ASH\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"ASN\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "        \"1HD2\": \"HD21\",\n",
    "        \"2HD2\": \"HD22\",\n",
    "    },\n",
    "    \"LYS\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "        \"HG2\": \"HG3\",\n",
    "        \"HG1\": \"HG2\",\n",
    "        \"HD2\": \"HD3\",\n",
    "        \"HD1\": \"HD2\",\n",
    "        \"HE2\": \"HE3\",\n",
    "        \"HE1\": \"HE2\",\n",
    "    },\n",
    "    \"SER\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"PRO\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "        \"HD2\": \"HD3\",\n",
    "        \"HD1\": \"HD2\",\n",
    "        \"HG2\": \"HG3\",\n",
    "        \"HG1\": \"HG2\",\n",
    "    },\n",
    "    \"MET\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "        \"HG2\": \"HG3\",\n",
    "        \"HG1\": \"HG2\",\n",
    "    },\n",
    "    \"TYR\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"HIE\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"HIP\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"HID\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"TRP\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"CYS\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "    \"CYX\": {\n",
    "        \"HB2\": \"HB3\",\n",
    "        \"HB1\": \"HB2\",\n",
    "    },\n",
    "}\n",
    "\n",
    "def correct_amino_acid_atom_names(npdb_i, resname, rename_mapping):\n",
    "    \"\"\"corrects the amino acid atom names according to the mapping provided\n",
    "\n",
    "    Args:\n",
    "        npdb_i: nested pdb data structure for a single residue\n",
    "        resname: the residue name\n",
    "        rename_mapping: a dictionary mapping old names to new names\n",
    "    \"\"\"\n",
    "    rename_atom_map = rename_mapping.get(resname, {})\n",
    "    if resname in rename_mapping:\n",
    "        for old_name, new_name in rename_mapping[resname].items():\n",
    "            npdb_i = [extract_and_replace(x, rename_atom_map) for x in npdb_i]\n",
    "            # certify that we have the alignment as expected for pdb files\n",
    "    return npdb_i\n",
    "\n",
    "def extract_and_replace(line, rename_mapping):\n",
    "    \"\"\"extracts the atom name and replaces it with the new name\"\"\"\n",
    "    atom_name = line[12:16].strip()\n",
    "    new_atom_name = rename_mapping.get(atom_name, atom_name)\n",
    "    if len(new_atom_name) == 4:\n",
    "        return line[:12] + new_atom_name + line[16:]\n",
    "    else:\n",
    "        # return left aligned atom name always with len() == 3 but with a \" \" in the beginning\n",
    "        return line[:12] + f\" {new_atom_name:<3}\" + line[16:]\n",
    "\n",
    "def fix_pdb(pdb_path:Path, rename_mapping):\n",
    "    renamed_pdb_path = pdb_path.with_name(pdb_path.stem + '_renamed.pdb')\n",
    "    with open(pdb_path) as f:\n",
    "        pdb_lines = f.readlines()\n",
    "\n",
    "    npdb = nest_pdb(pdb_lines)\n",
    "    npdb = asp_search(npdb)\n",
    "    \n",
    "    for i, res in enumerate(npdb):\n",
    "        resname = res[-1][17:20]\n",
    "        npdb[i] = correct_amino_acid_atom_names(npdb[i], resname, rename_mapping)\n",
    "    pdb_lines = unnest_pdb(npdb)\n",
    "    \n",
    "    with open(renamed_pdb_path, \"w\") as f:\n",
    "        for line in pdb_lines:\n",
    "            f.write(line)\n",
    "    return pdb_lines\n",
    "\n",
    "def cap_and_reindex_pdb(inp_pdb: Path):\n",
    "    \"\"\"Function that removes additionaly hydrogens from N terminal not covered\n",
    "    in our library files, caps the last residue and reindexes the atoms\n",
    "\n",
    "    Args:\n",
    "        inp_pdb: path for the pdb file\n",
    "    \"\"\"    \n",
    "    \n",
    "    pdb_df= read_pdb_to_dataframe(inp_pdb)\n",
    "    \n",
    "    # remove extra Hs from the first Gly residue\n",
    "    if pdb_df['residue_name'].values[0] == 'GLY':\n",
    "        first_residue = pdb_df['residue_seq_number'].values[0]\n",
    "        # remove atoms with atom_name H2 and H3, and rename H1 to H\n",
    "        subset_first = pdb_df[(pdb_df['residue_seq_number'] == first_residue) & (~pdb_df['atom_name'].isin(['H2', 'H3']))].copy()\n",
    "        subset_first['atom_name'] = subset_first['atom_name'].str.replace('H1', 'H')\n",
    "        rm_idxs = pdb_df.query('residue_seq_number == @first_residue').index\n",
    "        pdb_df = pd.concat([subset_first, pdb_df.drop(index=rm_idxs)], ignore_index=True)\n",
    "    \n",
    "    # cap the last residue\n",
    "    last_residue = pdb_df['residue_name'].values[-1]\n",
    "    last_residue_number = pdb_df['residue_seq_number'].values[-1]\n",
    "    if last_residue in ['ILE', 'NME']:\n",
    "        rm_idxs = pdb_df.query('residue_seq_number == @last_residue_number').index\n",
    "        pdb_df.drop(index=rm_idxs, inplace=True)\n",
    "    _len = len(pdb_df)\n",
    "    pdb_df['atom_serial_number'] = range(1, _len + 1)\n",
    "    write_dataframe_to_pdb(pdb_df, inp_pdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_paths = sorted(Path().glob('*/protein/protein.pdb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('bace/protein/protein.pdb'),\n",
       " PosixPath('bace_hunt/protein/protein.pdb'),\n",
       " PosixPath('bace_p2/protein/protein.pdb'),\n",
       " PosixPath('cdk2/protein/protein.pdb'),\n",
       " PosixPath('cdk8/protein/protein.pdb'),\n",
       " PosixPath('cmet/protein/protein.pdb'),\n",
       " PosixPath('eg5/protein/protein.pdb'),\n",
       " PosixPath('galectin/protein/protein.pdb'),\n",
       " PosixPath('hif2a/protein/protein.pdb'),\n",
       " PosixPath('hunt/protein/protein.pdb'),\n",
       " PosixPath('jnk1/protein/protein.pdb'),\n",
       " PosixPath('mcl1/protein/protein.pdb'),\n",
       " PosixPath('p2/protein/protein.pdb'),\n",
       " PosixPath('p38/protein/protein.pdb'),\n",
       " PosixPath('pde10/protein/protein.pdb'),\n",
       " PosixPath('pde2/protein/protein.pdb'),\n",
       " PosixPath('pfkfb3/protein/protein.pdb'),\n",
       " PosixPath('ptp1b/protein/protein.pdb'),\n",
       " PosixPath('shp2/protein/protein.pdb'),\n",
       " PosixPath('syk/protein/protein.pdb'),\n",
       " PosixPath('thrombin/protein/protein.pdb'),\n",
       " PosixPath('tnks2/protein/protein.pdb'),\n",
       " PosixPath('tyk2/protein/protein.pdb')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for pdb_path in pdb_paths:\n",
    "    fix_pdb(pdb_path, rename_mapping)\n",
    "    cap_and_reindex_pdb(pdb_path.with_stem(pdb_path.stem + '_renamed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe I can run qprep through the notebook already, so I get the COG of all the ligands, and then use to prepare the water spheres of the respective systems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
